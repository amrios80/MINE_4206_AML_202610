{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2dNwUTBZO8OE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Logo AML](https://github.com/nicolastibata/MINE_4206_AML_202610/blob/main/docs/logo.jpg?raw=true)"
      ],
      "metadata": {
        "id": "Fu--cYslMD7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Laboratorio 1 - Sesión 2: Regresión Polinomial y Regularizada**\n",
        "**Tutor: Nicolás Tibatá**\n",
        "\n",
        "## **Tabla de Contenido**\n",
        "\n",
        "[Contexto y objetivos](#scrollTo=kgcjzQ76ODRS)<br>\n",
        "[1. Introducción de los datos](#scrollTo=2dNwUTBZO8OE)<br>\n",
        "[2. Preparación y Modelamiento](#scrollTo=SlV42CI6PBoQ)<br>\n",
        "[3. Preguntas](#scrollTo=OCwUBTvxPRdS)<br>"
      ],
      "metadata": {
        "id": "Z8rWvJKiMTeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Contexto y Objetivos**\n",
        "\n",
        "Reducir las emisiones de CO2 es crucial para mitigar el cambio climático y minimizar sus efectos nocivos sobre el medio ambiente y el bienestar humano. Esto implica hacer la transición a fuentes de energía más limpias y renovables, mejorar la eficiencia energética, adoptar prácticas sostenibles y promover esfuerzos de conservación. El set de datos reúne información de emisiones de automotores e información de consumo de combustible.\n",
        "\n",
        "- Ver las implicaciones de las regularizaciones y relaciones polinomiales.\n",
        "- Aplicar pipelines para el preprocesamiento de datos, aplicar diferentes tipos de escaladores.\n",
        "- Realizar una busqueda del mejor modelo.\n",
        "\n",
        "**Datos:** [CO2 Emissions](https://www.kaggle.com/datasets/bhuviranga/co2-emissions)\n",
        "\n",
        "**Diccionario**\n",
        "| Columna | Descripción |\n",
        "| :--- | :--- |\n",
        "| **Make** | Nombre del fabricante de automotores. |\n",
        "| **Model** | Modelo del automotor. |\n",
        "| **Vehicle Class** | Clase de vehículo. |\n",
        "| **Engine Size (L)** | Tamaño del motor. Las unidades están expresadas en litros. |\n",
        "| **Transmission** | Tipo de transmisión del vehículo, automática o manual. |\n",
        "| **Fuel Type** | Tipo de combustible: *Regular Gasoline* (X), *Premium Gasoline* (Z), *Ethanol* (E), *Diesel* (D), *Natural Gas* (N). |\n",
        "| **Fuel Consumption City (L/100km)** | Consumo del vehículo en ciudad. Las unidades están expresadas en litros por kilómetro. |\n",
        "| **Fuel Consumption Hwy (L/100 km)** | Consumo del vehículo en carretera. Las unidades están expresadas en litros por kilómetro. |\n",
        "| **Fuel Consumption Comb (L/100 km)** | Consumo del vehículo en ciudad y en carretera. Las unidades están expresadas en litros por kilómetro.|\n",
        "| **Fuel Consumption Comb (mpg)** | Consumo del vehículo en ciudad y en carretera. Las unidades están expresadas en millas por galón. |\n",
        "| **CO2 Emissions(g/km)** | Cantidad de gramos emitidos de C02 por kilometro. |"
      ],
      "metadata": {
        "id": "kgcjzQ76ODRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Introducción a los datos**"
      ],
      "metadata": {
        "id": "2dNwUTBZO8OE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos o instalamos librerias necesarias\n",
        "!pip install ydata-profiling -q\n",
        "from ydata_profiling import ProfileReport\n",
        "# Acceso a credenciales\n",
        "import os\n",
        "from google.colab import files\n",
        "from google.colab import userdata\n",
        "# Manejo de datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Modelamiento\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, FunctionTransformer\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector"
      ],
      "metadata": {
        "id": "e7dFx0vTO717"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos los datos directamente de kaggle con las credenciales personales, pueden consultar cómo funciona [acá](https://www.kaggle.com/discussions/general/74235#2580958)."
      ],
      "metadata": {
        "id": "psFYt3eIUJJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('adrianamariarios')"
      ],
      "metadata": {
        "id": "AsfzvIkWm3k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PaCqt3MLnFI"
      },
      "outputs": [],
      "source": [
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('adrianamariarios')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('adrianamariarios')\n",
        "\n",
        "!kaggle datasets download -d bhuviranga/co2-emissions\n",
        "!unzip \"co2-emissions.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('CO2 Emissions.csv')\n",
        "data.info()\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "UFA38onUVgjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "pW5h8EpEVz_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Preparación y Modelamiento**"
      ],
      "metadata": {
        "id": "SlV42CI6PBoQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de preparar y modelar los datos, veamos un poco cómo se constituyen"
      ],
      "metadata": {
        "id": "L_0Q6n9fcNZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ProfileReport(data)"
      ],
      "metadata": {
        "id": "VFyLW26EcTAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¿Cuáles son los insights que encontramos?**\n",
        "- `Model` es una variable con muchos valores únicos (2053) lo cual hace que dicha variable se considere con una alta cardinalidad, esto genera ruido estadístico a nuestros modelos o problemas de alta dimensionalidad.\n",
        "- `Vehicle Type` es una variable que por sus características de cilindraje, engine size o el consumo son intrisecamente relacionadas, por lo tanto podemos descartarla.\n",
        "- Encontramos registros duplicados por lo tanto debemos eliminarlos.\n",
        "- Encontramos datos ausentes dentro de las columnas, en este caso en nuestro pipeline aplicamos un imputador de ausencias."
      ],
      "metadata": {
        "id": "3_XTKAZSPu6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preparación**"
      ],
      "metadata": {
        "id": "BSdtQQkIPI_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Separar los datos en entrenamiento y test -> SIEMPRE\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=71)"
      ],
      "metadata": {
        "id": "79XFx21EPIT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables a eliminar\n",
        "drop_fields = ['Model', 'Vehicle Class']\n",
        "# Variable objetivo\n",
        "target_feature = 'CO2 Emissions(g/km)'\n",
        "# Variables categoricas\n",
        "categorical_features = ['Make', 'Transmission', 'Fuel Type']\n",
        "\n",
        "# Preprocesamiento\n",
        "def preprocess(df):\n",
        "  print(f\"Total de filas duplicadas eliminadas: {df.duplicated().sum().sum()}\")\n",
        "  df = df.drop_duplicates() # Eliminamos duplicados\n",
        "  df = df.drop(drop_fields, axis = 1) # Eliminamos columnas que no vamos a usar\n",
        "  X_data, y_variable = df.drop([target_feature], axis=1), df[target_feature] # Separamos nuestro target de las variables explicativas\n",
        "  return X_data, y_variable"
      ],
      "metadata": {
        "id": "k9SjTEFscV8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = preprocess(train_data)\n",
        "display(X_train)\n",
        "display(y_train)"
      ],
      "metadata": {
        "id": "X-MX6m50cyIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definamos las variables numericas\n",
        "num_features = list(set(X_train.columns) - set(categorical_features))\n",
        "num_features"
      ],
      "metadata": {
        "id": "je1KR9FPdMxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Pipeline**"
      ],
      "metadata": {
        "id": "B87hIjHOdWGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Qué es un pipeline? El pipeline permite ensamblar varios pasos y validarlos de forma cruzada mientras se ajustan diferentes parámetros. Esto nos sirve para replicar nuestro procesamiento a diferentes set de datos o diferentes algoritmos sin tener que pasar otra vez por todas las lineas de código."
      ],
      "metadata": {
        "id": "UGSQUNande1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Funciones complementarias\n",
        "\n",
        "# Funcion que hace rename a las categorias\n",
        "def fix_cat_values(df):\n",
        "  for column in df.columns:\n",
        "    if column == 'Fuel Type':\n",
        "      fuel_labels = {'X': 'Regular Gasoline', 'Z': 'Premium Gasoline', 'E': 'Ethanol', 'D': 'Diesel', 'N': 'Natural Gas'}\n",
        "      df['Fuel Type'] = df['Fuel Type'].replace(fuel_labels)\n",
        "    elif column == 'Transmission':\n",
        "      df['Transmission'] = df['Transmission'].apply(lambda x: 'Automatic' if x.startswith('A') else 'Manual')\n",
        "  return df"
      ],
      "metadata": {
        "id": "Gkp4xl-hdobZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Construcción del Pipeline\n",
        "\n",
        "# num_transformer reemplaza los valores ausentes por el mean para las variables numéricas\n",
        "num_transformer = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean'))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# cat_transformer aplica de primer paso nuestra funcion complementaria y luego sobre ese resultado aplica OneHotEncoder\n",
        "cat_transformer = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', FunctionTransformer(fix_cat_values, validate=False)),\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "HHxg7amldwT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez que hemos definido los transformadores, definimos los pasos (`steps`), que permitirán construir y ejecutar el Pipeline. Los pasos son los siguientes:\n",
        "\n",
        "1.   `num`, incluye el transformador numérico y la relación de las columnas numéricas haciendo uso de `make_column_selector`.\n",
        "2.   `cat`, incluye el transformador categórico y la relación de dichas columnas haciendo uso de `make_column_selector`."
      ],
      "metadata": {
        "id": "2eFb_0Wld8rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", num_transformer, make_column_selector(dtype_include=np.number)),\n",
        "        (\"cat\", cat_transformer, make_column_selector(dtype_include=object))\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "dRg8jwVqd-Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizamos nuestro pipeline\n",
        "pipe = Pipeline(steps=[\n",
        "    ('column_transformer', preprocessor)\n",
        "])\n",
        "\n",
        "pipe"
      ],
      "metadata": {
        "id": "6TSH8ksPeAc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "iI02P-HMeGl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_column_names = pipe['column_transformer'].transformers_[1][1][1].get_feature_names_out()\n",
        "num_column_names = pipe['column_transformer'].transformers_[0][1].feature_names_in_\n",
        "col_names = list(num_column_names) + list(cat_column_names)\n",
        "\n",
        "col_names"
      ],
      "metadata": {
        "id": "8Kch2pOje-be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(pipe.fit_transform(X_train).toarray(), columns=col_names)"
      ],
      "metadata": {
        "id": "7dcRSsrreMry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si quieres saber más sobre como funciona el OneHotEncoder: o sus alternativas, lo puedes consultar [acá](https://scikit--learn-org.translate.goog/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html?_x_tr_sl=en&_x_tr_tl=es&_x_tr_hl=es&_x_tr_pto=tc)"
      ],
      "metadata": {
        "id": "OFhzwdRObgU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Modelamiento**"
      ],
      "metadata": {
        "id": "GyLuLIDOPLei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Modelo: Regresión Lineal**"
      ],
      "metadata": {
        "id": "CiGnSTFhlFov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimators_lr = [\n",
        "        ('transform',preprocessor),\n",
        "        ('regression', LinearRegression())\n",
        "]\n",
        "\n",
        "pipe_lr = Pipeline(estimators_lr)\n",
        "\n",
        "pipe_lr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "dSn5r-bYlM3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef_lr = dict(zip(col_names, pipe_lr[\"regression\"].coef_))\n",
        "for k,v in coef_lr.items():\n",
        "    print(f'{k} = {v:,.2f}')"
      ],
      "metadata": {
        "id": "h8wZ-8R0lRDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluemos el modelo\n",
        "# 1. Apliquemos los mismos pasos al conjunto de test\n",
        "X_test, y_test = preprocess(test_data)\n",
        "display(X_test)\n",
        "display(y_test)"
      ],
      "metadata": {
        "id": "CX-l4vmAlV68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test_lr = pipe_lr.predict(X_test)\n",
        "y_pred_test_lr"
      ],
      "metadata": {
        "id": "Qp0Y0q5gmAqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Así de facil con `pipe_lr` aplicamos los pasos del preprocesamiento y además evaluamos nuestro modelo con el conjunto de test"
      ],
      "metadata": {
        "id": "RXFzOzxkmFHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n,p = X_test.shape\n",
        "\n",
        "print('------------ Regresión Lineal ------------')\n",
        "print(\"Sum of squares (MSE): %.2f\" % mean_squared_error(y_test, y_pred_test_lr))\n",
        "print(\"Root of sum of squares (RMSE): %.2f\" % mean_squared_error(y_test, y_pred_test_lr) ** (1/2))\n",
        "print(\"R2-score: %.5f\" % r2_score(y_test, y_pred_test_lr) )\n",
        "print(\"Adj R2-score: %.5f\" % ( 1-(1-r2_score(y_test, y_pred_test_lr))*(n-1)/(n-p-1)) )"
      ],
      "metadata": {
        "id": "39uM3uGwlYF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,figsize=(14,7))\n",
        "\n",
        "xvals = list(range(len(y_test[:50])))\n",
        "axs.plot(xvals, y_pred_test_lr[:50],'bo-', label='Predicción')\n",
        "axs.plot(xvals, y_test[:50],'ro-', label='Real')\n",
        "\n",
        "axs.set(title='Modelo con Regresión Lineal', ylabel=y_test.name)\n",
        "axs.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U_lZGQ5UlaLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Modelo: Regresión Polinomial**"
      ],
      "metadata": {
        "id": "KSBgXYVElfhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimators_poly = [\n",
        "        ('transform',preprocessor),\n",
        "        ('poly',PolynomialFeatures(degree=3)),\n",
        "        ('regression', LinearRegression())\n",
        "]\n",
        "\n",
        "pipe_poly = Pipeline(estimators_poly)\n",
        "\n",
        "pipe_poly.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "DQaR066fle2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef_lr = dict(zip(col_names, pipe_poly[\"regression\"].coef_))\n",
        "for k,v in coef_lr.items():\n",
        "    print(f'{k} = {v:,.2f}')"
      ],
      "metadata": {
        "id": "JKVxM-NFmi-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos nuestro modelo con test\n",
        "y_pred_test_poly = pipe_poly.predict(X_test)\n",
        "y_pred_test_poly"
      ],
      "metadata": {
        "id": "mXCtibEtmndY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n,p = X_test.shape\n",
        "\n",
        "print('------------ Regresión con Transformación Polinomial ------------')\n",
        "print(\"Sum of squares (MSE): %.2f\" % mean_squared_error(y_test, y_pred_test_poly))\n",
        "print(\"Root of sum of squares (RMSE): %.2f\" % mean_squared_error(y_test, y_pred_test_poly) ** (1/2))\n",
        "print(\"R2-score: %.5f\" % r2_score(y_test, y_pred_test_poly) )\n",
        "print(\"Adj R2-score: %.5f\" % ( 1-(1-r2_score(y_test, y_pred_test_poly))*(n-1)/(n-p-1)) )"
      ],
      "metadata": {
        "id": "yJA1rXk2mrxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,figsize=(14,7))\n",
        "\n",
        "xvals = list(range(len(y_test[:50])))\n",
        "axs.plot(xvals, y_pred_test_poly[:50],'bo-', label='Predicción')\n",
        "axs.plot(xvals, y_test[:50],'ro-', label='Real')\n",
        "\n",
        "axs.set(title='Modelo con Transformación Polinomial', ylabel=y_test.name)\n",
        "axs.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q24pLmsfmuhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Modelo: Regresión Lineal con regularización L1**"
      ],
      "metadata": {
        "id": "2cSbEMGZm0wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimators_lasso = [\n",
        "        ('transform',preprocessor),\n",
        "        ('lasso', Lasso(alpha=8))\n",
        "]\n",
        "\n",
        "pipe_lasso = Pipeline(estimators_lasso)\n",
        "\n",
        "pipe_lasso.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "KUflQmpJm5f7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef_lr = dict(zip(col_names, pipe_lasso[\"lasso\"].coef_))\n",
        "for k,v in coef_lr.items():\n",
        "    print(f'{k} = {v:,.2f}')"
      ],
      "metadata": {
        "id": "5lf-WZFbm8Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos nuestro modelo\n",
        "y_pred_test_lasso = pipe_lasso.predict(X_test)\n",
        "y_pred_test_lasso"
      ],
      "metadata": {
        "id": "ARD2mYPAm9RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n,p = X_test.shape\n",
        "\n",
        "print('------------ Regresión Lasso ------------')\n",
        "print(\"Sum of squares (MSE): %.2f\" % mean_squared_error(y_test, y_pred_test_lasso))\n",
        "print(\"Root of sum of squares (RMSE): %.2f\" % mean_squared_error(y_test, y_pred_test_lasso) ** (1/2))\n",
        "print(\"R2-score: %.5f\" % r2_score(y_test, y_pred_test_lasso) )\n",
        "print(\"Adj R2-score: %.5f\" % ( 1-(1-r2_score(y_test, y_pred_test_lasso))*(n-1)/(n-p-1)) )"
      ],
      "metadata": {
        "id": "d0h2663DoDDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,figsize=(14,7))\n",
        "\n",
        "xvals = list(range(len(y_test[:50])))\n",
        "axs.plot(xvals, y_pred_test_lasso[:50],'bo-', label='Predicción')\n",
        "axs.plot(xvals, y_test[:50],'ro-', label='Real')\n",
        "\n",
        "axs.set(title='Modelo con Regularización Lasso', ylabel=y_test.name)\n",
        "axs.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hJ9qCVewomgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Búsqueda del mejor modelo**\n",
        "\n",
        "En este caso no solo usaremos un único modelo, sino diferentes combinaciones posibles. Para esto usamos Grid Search CV"
      ],
      "metadata": {
        "id": "pawoCyGuvZb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimators_best = [\n",
        "        ('transform', preprocessor),\n",
        "        ('polinomial',PolynomialFeatures()),\n",
        "        ('regression', Lasso())\n",
        "]\n",
        "\n",
        "pipe_best = Pipeline(estimators_best)\n",
        "\n",
        "# Parametros de la busqueda\n",
        "parameters = {\n",
        "              'polinomial__degree':[2,3],\n",
        "              'regression__alpha': [0.01, 1],\n",
        "              'transform__num': [StandardScaler(), MinMaxScaler(), 'passthrough'],\n",
        "              'transform__cat': [OneHotEncoder(handle_unknown='ignore'), OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=0)]\n",
        "              }\n",
        "\n",
        "grid_search = GridSearchCV(pipe_best, parameters, verbose=2, scoring='neg_mean_squared_error', cv=5)"
      ],
      "metadata": {
        "id": "LrF_nohMvZIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Zu_ihzbyvq3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "pd.DataFrame(grid_search.cv_results_)"
      ],
      "metadata": {
        "id": "9sLx1xTSv1YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "QO4e9Igdv5jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos nuestro modelo\n",
        "y_pred_train = best_model.predict(X_train)\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "y_pred_train"
      ],
      "metadata": {
        "id": "SgmUzKftwHsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n,p = X_train.shape\n",
        "\n",
        "print('------------ Regresión Lasso con entrenamiento------------')\n",
        "print(\"Residual sum of squares (MSE): %.2f\" % mean_squared_error(y_train, y_pred_train))\n",
        "print(\"Root of sum of squares (RMSE): %.2f\" % mean_squared_error(y_train, y_pred_train) ** (1/2))\n",
        "print(\"R2-score: %.5f\" % r2_score(y_train, y_pred_train) )\n",
        "print(\"Adj R2-score: %.5f\" % ( 1-(1-r2_score(y_train, y_pred_train))*(n-1)/(n-p-1)) )\n",
        "\n",
        "n,p = X_test.shape\n",
        "\n",
        "print('------------ Regresión Lasso con evaluación ------------')\n",
        "print(\"Residual sum of squares (MSE): %.2f\" % mean_squared_error(y_test, y_pred_test))\n",
        "print(\"Root of sum of squares (RMSE): %.2f\" % mean_squared_error(y_test, y_pred_test) ** (1/2))\n",
        "print(\"R2-score: %.5f\" % r2_score(y_test, y_pred_test) )\n",
        "print(\"Adj R2-score: %.5f\" % ( 1-(1-r2_score(y_test, y_pred_test))*(n-1)/(n-p-1)) )\n",
        "\n",
        "# No hay indicios de sobreajuste"
      ],
      "metadata": {
        "id": "V0XTNFWTwM6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "fig, axs = plt.subplots(2,figsize=(20,10))\n",
        "a = 1000\n",
        "b= 1080\n",
        "\n",
        "xvals = list(range(b-a))\n",
        "axs[0].plot(xvals, y_pred_train[a:b],'bo-', label='Predicción')\n",
        "axs[0].plot(xvals, y_train[a:b],'ro-', label='Real')\n",
        "\n",
        "axs[1].plot(xvals, y_pred_test[a:b],'bo-', label='Predicción')\n",
        "axs[1].plot(xvals, y_test[a:b],'ro-', label='Real')\n",
        "\n",
        "axs[0].set(title='Predicción con Regresión Lasso con CV - Entrenamiento', ylabel=y_train.name)\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].set(title='Predicción con Regresión Lasso con CV - Evaluación', ylabel=y_train.name)\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-JsQT_ycwTfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya con nuestro mejor modelo encontrado y teniendo un rendimiento esperado en producción, podremos determinar la importancia de las variables del modelo. Para ello se obtuvo el siguiente resultado."
      ],
      "metadata": {
        "id": "IimoNblXwV6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_model = best_model['regression']\n",
        "trans_df = best_model['transform'].transform(X_test)\n",
        "fake_df = best_model['polinomial'].transform(trans_df)\n",
        "\n",
        "cat_names = best_model['transform'].transformers_[1][1].get_feature_names_out()\n",
        "num_names = best_model['transform'].transformers_[0][2]#.feature_names_in_\n",
        "col_names = list(num_names) + list(cat_names)\n",
        "\n",
        "print(f'Intercepto: {lasso_model.intercept_}')\n",
        "coef = list(zip(['Intercepto'] + list(col_names), [lasso_model.intercept_] + list(lasso_model.coef_)))\n",
        "coef = pd.DataFrame(coef,columns=['Variable','Parámetro'])\n",
        "coef"
      ],
      "metadata": {
        "id": "zMB56Eujxb9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Preguntas**"
      ],
      "metadata": {
        "id": "OCwUBTvxPRdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Cree un pipeline con el algoritmo de su seleccion donde incluya un minmaxScaler a las variables que aplique\n",
        "\n",
        "```\n",
        "num_transformer = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', MinMaxScaler())  # Adicion acá\n",
        "    ]\n",
        ")\n",
        "\n",
        "cat_transformer = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', FunctionTransformer(fix_cat_values, validate=False)),\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", num_transformer, make_column_selector(dtype_include=np.number)),\n",
        "        (\"cat\", cat_transformer, make_column_selector(dtype_include=object))\n",
        "    ]\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "7w1vehO8u6Nc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. ¿Cuáles son las diferencias entre regresión lineal con transformación polinomial y regresión regularizada Lasso?\n",
        "3. ¿Qué otro espacio de búsqueda o hiperparámetros serían buenos de buscar en este modelo?.\n",
        "4. La columna `Make` puede considerarse una variable de alta cardinalidad. ¿Cómo serían los resultados si se construye un modelo sin esta variable?"
      ],
      "metadata": {
        "id": "2VYgZcWYqv9l"
      }
    }
  ]
}